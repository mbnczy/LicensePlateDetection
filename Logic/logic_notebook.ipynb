{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_det_model_path = '/Users/banoczymartin/Library/Mobile Documents/com~apple~CloudDocs/OE/platedetector/models/YOLOv8/yolov8n_90e_cust/runs/detect/train4/weights/best.pt'\n",
    "testvideo_path = '/Users/banoczymartin/Library/Mobile Documents/com~apple~CloudDocs/OE/platedetector/video_data/testvideo_highway_mp4.mp4'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_det_model=YOLO('yolov8n.pt')\n",
    "vehicle_ids = [2,3,4,5,6,7,8]\n",
    "plate_det_model = YOLO(plate_det_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New class needed for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "  \"\"\"\n",
    "  w = np.sqrt(x[2] * x[3])\n",
    "  h = x[2] / w\n",
    "  if(score==None):\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "  else:\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "class KalmanBoxTracker(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.time_since_update = 0\n",
    "    self.id = KalmanBoxTracker.count\n",
    "    KalmanBoxTracker.count += 1\n",
    "    self.history = []\n",
    "    self.hits = 0\n",
    "    self.hit_streak = 0\n",
    "    self.age = 0\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.time_since_update = 0\n",
    "    self.history = []\n",
    "    self.hits += 1\n",
    "    self.hit_streak += 1\n",
    "    self.kf.update(convert_bbox_to_z(bbox))\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "def linear_assignment(cost_matrix):\n",
    "    try:\n",
    "        import lap\n",
    "        _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "        return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "    except ImportError:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        x, y = linear_sum_assignment(cost_matrix)\n",
    "        return np.array(list(zip(x, y)))\n",
    "    \n",
    "def iou_batch(bb_test, bb_gt):\n",
    "    bb_gt = np.expand_dims(bb_gt, 0)\n",
    "    bb_test = np.expand_dims(bb_test, 1)\n",
    "\n",
    "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "     + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "    return(o)  \n",
    "\n",
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "    if(len(trackers)==0):\n",
    "      return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "    iou_matrix = iou_batch(detections, trackers)\n",
    "    if min(iou_matrix.shape) > 0:\n",
    "      a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "      if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "          matched_indices = np.stack(np.where(a), axis=1)\n",
    "      else:\n",
    "        matched_indices = linear_assignment(-iou_matrix)\n",
    "    else:\n",
    "      matched_indices = np.empty(shape=(0,2))\n",
    "    unmatched_detections = []\n",
    "    for d, det in enumerate(detections):\n",
    "      if(d not in matched_indices[:,0]):\n",
    "        unmatched_detections.append(d)\n",
    "    unmatched_trackers = []\n",
    "    for t, trk in enumerate(trackers):\n",
    "      if(t not in matched_indices[:,1]):\n",
    "        unmatched_trackers.append(t)\n",
    "    #filter out matched with low IOU\n",
    "    matches = []\n",
    "    for m in matched_indices:\n",
    "      if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "        unmatched_detections.append(m[0])\n",
    "        unmatched_trackers.append(m[1])\n",
    "      else:\n",
    "        matches.append(m.reshape(1,2))\n",
    "    if(len(matches)==0):\n",
    "      matches = np.empty((0,2),dtype=int)\n",
    "    else:\n",
    "      matches = np.concatenate(matches,axis=0)\n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class MotionTracker(object):\n",
    "    def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.trackers = []\n",
    "        self.frame_count = 0\n",
    "    \n",
    "    \n",
    "    def update(self, dets=np.empty((0, 5))):\n",
    "        self.frame_count += 1\n",
    "        # get predicted locations from existing trackers.\n",
    "        trks = np.zeros((len(self.trackers), 5))\n",
    "        to_del = []\n",
    "        ret = []\n",
    "        for t, trk in enumerate(trks):\n",
    "            pos = self.trackers[t].predict()[0]\n",
    "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "            if np.any(np.isnan(pos)):\n",
    "                to_del.append(t)\n",
    "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "        for t in reversed(to_del):\n",
    "            self.trackers.pop(t)\n",
    "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "         # update matched trackers with assigned detections\n",
    "        for m in matched:\n",
    "            self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "        # create and initialise new trackers for unmatched detections\n",
    "        for i in unmatched_dets:\n",
    "            trk = KalmanBoxTracker(dets[i,:])\n",
    "            self.trackers.append(trk)\n",
    "        i = len(self.trackers)\n",
    "        for trk in reversed(self.trackers):\n",
    "            d = trk.get_state()[0]\n",
    "            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "                ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "            i -= 1\n",
    "            # remove dead tracklet\n",
    "            if(trk.time_since_update > self.max_age):\n",
    "                self.trackers.pop(i)\n",
    "        if(len(ret)>0):\n",
    "            return np.concatenate(ret)\n",
    "        return np.empty((0,5))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5965.045] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2386) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin\n",
      "[ WARN:0@5965.045] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2402) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module uridecodebin16 reported: Your GStreamer installation is missing a plug-in.\n",
      "[ WARN:0@5965.045] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@5965.045] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 130.3ms\n",
      "Speed: 8.4ms preprocess, 130.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 114.3ms\n",
      "Speed: 4.4ms preprocess, 114.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 104.7ms\n",
      "Speed: 3.1ms preprocess, 104.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 236.8ms\n",
      "Speed: 4.6ms preprocess, 236.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 155.2ms\n",
      "Speed: 5.8ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 119.1ms\n",
      "Speed: 3.4ms preprocess, 119.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 96.9ms\n",
      "Speed: 3.1ms preprocess, 96.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 100.6ms\n",
      "Speed: 3.0ms preprocess, 100.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 87.3ms\n",
      "Speed: 3.4ms preprocess, 87.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 92.7ms\n",
      "Speed: 3.0ms preprocess, 92.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 80.6ms\n",
      "Speed: 2.7ms preprocess, 80.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 85.0ms\n",
      "Speed: 2.9ms preprocess, 85.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 100.6ms\n",
      "Speed: 3.0ms preprocess, 100.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 23 cars, 2 buss, 2 trucks, 109.0ms\n",
      "Speed: 3.4ms preprocess, 109.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 100.1ms\n",
      "Speed: 3.8ms preprocess, 100.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 21 cars, 2 buss, 2 trucks, 90.2ms\n",
      "Speed: 3.2ms preprocess, 90.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 82.2ms\n",
      "Speed: 3.2ms preprocess, 82.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 21 cars, 2 buss, 2 trucks, 100.4ms\n",
      "Speed: 2.8ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 licenses, 91.8ms\n",
      "Speed: 3.6ms preprocess, 91.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355.5145263671875, 719.653564453125, 461.53436279296875, 760.0565185546875, 0.4649117887020111, 0.0], [986.7059326171875, 815.9781494140625, 1114.87548828125, 849.3248901367188, 0.33637407422065735, 0.0], [245.34632873535156, 1164.4976806640625, 389.18267822265625, 1208.0, 0.3338821232318878, 0.0], [1160.2286376953125, 1149.0068359375, 1294.4239501953125, 1204.539306640625, 0.2977857291698456, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "video_capture = cv2.VideoCapture(testvideo_path)\n",
    "\n",
    "\n",
    "mot_trckr = MotionTracker()\n",
    "ret = True\n",
    "indexer=0\n",
    "while ret:\n",
    "    if (video_capture.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if ret and indexer<10:\n",
    "        \n",
    "        det_objs = vehicle_det_model(frame)[0]\n",
    "        vehicles=[]\n",
    "        for det_obj in det_objs.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = det_obj\n",
    "            if int(class_id) in vehicle_ids:\n",
    "                vehicles.append([x1, y1, x2, y2, score])\n",
    "        \n",
    "        track_ids = mot_trckr.update(np.asarray(vehicles))\n",
    "\n",
    "        plates=[]\n",
    "        det_lps = plate_det_model(frame)[0]\n",
    "        for det_lp in det_lps.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = det_lp\n",
    "            plates.append([x1, y1, x2, y2, score, class_id])\n",
    "            #assign license plate to vehicle\n",
    "            #vehicle_x1,vehicle_y1,vehicle_x2,vehicle_y2,vehicle_id = PlateToVehicle(det_lp,)\n",
    "        \n",
    "    indexer+=1\n",
    "print(plates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
